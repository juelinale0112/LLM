# LLM
OpenAI | Streamlit | Langchain 
WORKING OF THE MODEL:

Integration of OpenAI, LangChain, and Streamlit to create a user interface for interacting with data using a Language Model (LLM). Here's how each component works together:

1. OpenAI:
   - OpenAI provides a powerful language model called GPT-3.5 Turbo (or other models like GPT-4, as mentioned in your code).
   - It exposes an API that allows developers to send text prompts and receive natural language responses generated by the model.

2. LangChain:
   - LangChain appears to be a custom library or integration used to facilitate interactions with the OpenAI model in a more conversational manner and to work with data stored in a Pandas DataFrame.
   - It includes functionalities for creating an agent that interacts with the OpenAI model and the data in the DataFrame.
   - LangChain likely includes abstractions for simplifying interactions with OpenAI, handling conversation history, and structuring conversations with the model.

3. Streamlit:
   - Streamlit is a Python library for building web applications with minimal code. It is often used for creating interactive data applications and dashboards.
   - In this case, Streamlit is used to create a user interface (UI) for interacting with the LangChain agent and the data.
   - Streamlit provides components like `st.file_uploader`, `st.sidebar`, `st.chat_message`, and `st.chat_input` to build the UI elements.

Here's how they work together:

- The Streamlit app is initialized with a basic UI structure. Users can upload a data file, provide their OpenAI API key in the sidebar, and interact with a chat-like interface.
- When a user uploads a data file, Streamlit's `st.file_uploader` component allows them to select a file with supported formats like CSV, XLS, etc.
- The LangChain library is used to create a conversational agent (`pandas_df_agent`) that interacts with the OpenAI model (`llm`) and the Pandas DataFrame (`df`).
- When a user enters a query using `st.chat_input`, the LangChain agent sends the user's question to the OpenAI model.
- The OpenAI model generates a response based on the input question and potentially the data in the DataFrame. The response is displayed using `st.chat_message` in the Streamlit UI.
- The conversation history is maintained in `st.session_state.messages` to display the entire conversation.

In summary, OpenAI is responsible for generating natural language responses, LangChain helps structure the interaction and handles the DataFrame, and Streamlit provides the user interface to upload data and interact with the chat-like interface. Together, they enable users to have a conversational experience with the data using the power of the OpenAI language model.

TO RUN: streamlit run app2.py
